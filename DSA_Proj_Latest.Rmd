---
title: "DSA301 Project"
author: "Everyone"
output: html_document
---

##Loading Packages
```{r cars, include=FALSE}
rm(list = ls())
library(jsonlite)
library(lubridate)
library(forecast)
library(urca)
library(TSstudio)
library(prophet)
library(randomForest)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(randomForest) # for RF modelling 
#source("dataprocessing.R")
```

### Reading CSV, Processing into TS Object, Visualisation of Data
```{r}
daily_data = read_csv('trainvaldf.csv', show_col_types = FALSE)
# train = get_train_df(daily_data)
# val = get_val_df(daily_data)

# Putting data into TS Object
msts_wiki_daily = daily_data$views %>% msts(seasonal.periods = c(7, 365), start =c(2015, as.numeric(format(daily_data$date[1], "%j"))))

# Creating Train and Test Set
train_size = length(daily_data$date[year(daily_data$date) < 2021])
val_size = dim(daily_data)[1] - train_size

msts_split <- ts_split(msts_wiki_daily, sample.out = val_size)
msts_train = msts_split$train
msts_test = msts_split$test
```

###Visualising STL decomposition
```{r}
daily_train_decomp = mstl(msts_train)
seasadj_wiki <- seasadj(daily_train_decomp)
autoplot(daily_train_decomp)
# Both the yearly seasonal pattern and the weekly seasonal pattern seem significant (in terms of impact on overall data), and therefore we do not rule any of them out at the moment.
```
## Differencing Seasonal Adjusted Component
```{r}
#No differencing: Test stat = 5
# new = 6.483
  seasadj_wiki %>% ur.kpss() %>% summary()

#Test stat = 0.011
# new = 0.0102
seasadj_wiki %>% 
  diff(lag =1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0142 
# new = 0.0137
seasadj_wiki %>% 
  diff(lag =7)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.003
# new = 0.0026
seasadj_wiki %>% 
  diff(lag =7)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 2.2636
# new = 2.2177
seasadj_wiki %>% 
  diff(lag = 365)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0143
# new = 0.0137
seasadj_wiki %>% 
  diff(lag =365)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()
```


##Benchmark Models
###Benchmark Model Creation
```{r}
b1 <- stlf(msts_train, method = "naive", robust = T, h = val_size)
b2 <- stlf(msts_train, method = "rwdrift", robust = T, h = val_size)
checkresiduals(b1)
checkresiduals(b2)
accuracy(b1, msts_test)
accuracy(b2, msts_test)
# b1 RMSE - 17.005684
# b2 RMSE - 17.835712

# Ljung Box Test - We reject the null hypothesis that residuals are independently distributed, and we conclude that there is serial correlation. 
```
### Plotting Results
```{r}
autoplot(b1)
autoplot(b2)
# TRY TO PLOT THIS OUT
```

##ARIMA Models
###ACF & PACF Analysis for Differenced & Undifferenced Seasonal Adjusted Component
```{r}
# These two approaches to differencing yielded the lowest p value for the KPSS test.
trans_seasadj_wiki_1 <- seasadj_wiki %>%diff(lag = 1)
trans_seasadj_wiki_2 <- seasadj_wiki %>%diff(lag = 7)%>%diff(lag = 1)
autoplot(trans_seasadj_wiki_1)
autoplot(trans_seasadj_wiki_2)

ggtsdisplay(seasadj_wiki)
pacf(seasadj_wiki)
acf(seasadj_wiki)
# ACF is slowly decreasing. This means that there is high autocorrelation with each lagged variable, suggesting that there is a unit room in the data and it is not stationary. This confirms what we had found earlier. We will look at the ACF and PACF of the variable based on the taking the difference, suggested by the KPSS test.

ggtsdisplay(trans_seasadj_wiki_1)
pacf(trans_seasadj_wiki_1)
acf(trans_seasadj_wiki_1)

# ACF at seasonal lags shows slow decrease. 
# Non seasonal we see a sharp dropoff in ACF almost immediately after the second lag, suggesting it might be a MA(2)

ggtsdisplay(trans_seasadj_wiki_2)
pacf(trans_seasadj_wiki_2)
acf(trans_seasadj_wiki_2)
## Non seasonal AR 2? Seasonal AR? Seasonal MA (1)? Non seasonal MA(3)? 
```
###Shortlisting of ARIMA Models based of AICc
```{r}
# Using autoarima
A0 <- auto.arima(ts(seasadj_wiki, frequency = 7)) #(4,1,1)(2,0,2)[7]

# Variations based on the 1 non seasonal differencing

A2 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,0,3), period = 7))

# Model 4 is problematic, according to R data is not stationary
A4 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,0,2), period = 7))

# Variations based on having both seasonal and non seasonal differencing

A6 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,1,1), period = 7))
A7 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,1,3), period = 7))

model_AIC = data.frame(model = c("A0","A2", "A4", "A6","A7"),
                       AIC = c(A0$aic, A2$aic, A4$aic, A6$aic, A7$aic))

model_AIC
```

###Checking Residuals & Accuracy of Shortlisted ARIMA Models
```{r}
#Only only that passed were (4,1,3)(2,1,2)[7] and (4,1,3)(1,0,2)[7]

f0 = stlm(msts_train, modelfunction = Arima, order=c(4,1,1),
         seasonal = list(order = c(2,0,2), period = 7), robust = T)

f2 = stlm(msts_train, modelfunction = Arima, order=c(2,1,3),
         seasonal = list(order = c(2,0,3), period = 7), robust = T) 

f4 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3),
         seasonal = list(order = c(2,0,2), period = 7), robust = T)


f6 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3), 
         seasonal = list(order = c(2,1,1), period = 7), robust = T) 

f7 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3), 
          seasonal = list(order = c(2,1,3), period = 7), robust = T)


checkresiduals(forecast(f0, h = val_size))
checkresiduals(forecast(f2, h= val_size))
checkresiduals(forecast(f4, h = val_size))
checkresiduals(forecast(f6, h = val_size))
checkresiduals(forecast(f7, h = val_size))

#Only f4, f6, f7 passed the Ljung-Box Test for the train set
accuracy(forecast(f4), msts_test)
accuracy(forecast(f6), msts_test)
accuracy(forecast(f7), msts_test)


```

```{r}

plot_info = function(model){
  autoplot(msts_wiki_daily, series = "Original")+autolayer(forecast(model, h = val_size), PI = F, alpha = 0.9, col = "red", series = "Forecast")+ scale_colour_manual(values=c("Original"="black","Forecast"="red"),
                      breaks=c("Original","Forecast"))  
}

plot_info(f7)
```



## Facebook Prophet
```{r}
prophet_data = rename(daily_data, y = views, ds = date)
prophet_train = slice_head(prophet_data, n = train_size)
prophet_test = slice_tail(prophet_data, n = val_size)

model = prophet(prophet_train, daily.seasonality = FALSE)

# Prediction
future = make_future_dataframe(model, periods = dim(prophet_test)[1])
prophet_forecast = predict(model, future) %>% slice_tail(., n = dim(prophet_test)[1])
accuracy(prophet_test$y, prophet_forecast$yhat)

# accuracy(forecast(f7, h=dim(prophet_test[1])), msts_test)
# accuracy(forecast(f7), msts_test)

# Evaluation
# prophet_plot_components(model, prophet_forecast)
# autoplot(prophet_forecast$yhat)

x_axes = seq(1:(length(prophet_forecast$yhat)))
plot(x_axes, prophet_test$y, type="l", col="red", lwd=2)
lines(x_axes, prophet_forecast$yhat, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)
```

## ARIMA-X with 2020 Outlier
```{r}
daily_data$y2020 = sapply(daily_data$date, function(x) {
  if (year(x) ==2020) {return(1)}
  return(0)
})

adj2020 = daily_data$y2020[1:train_size]
# length(daily_data$y2020[(train_size+1):(train_size+test_size)])

testA1 = auto.arima(ts(seasadj_wiki, frequency = 7), xreg = adj2020)
```

```{r}
f4_adj = stlm(msts_train, modelfunction = Arima, order=c(3,1,3),
         seasonal = list(order = c(2,0,2), period = 7), robust = T, xreg = y2020)

accuracy(forecast(f4_adj), msts_test)

?stlm()
```


