---
title: "DSA301 Project"
author: "Everyone"
output: html_document
---
Questions:
1. Decompose first or transform first (benchmark models)
3. How to read the PACF & ACF graphs? Currently just using guess and check from changing models provided by auto.arima

##Loading Packages
```{r cars}
# install.packages("pageviews")
# install.packages("jsonlite")
# install.packages("lubridate")
library(jsonlite)
library(pageviews)
library(lubridate)
library(dplyr)
library(forecast)
library(urca)
library(TSstudio)
rm(list = ls())
```

##Getting the daily data
```{r pressure, echo=FALSE}
project = "en.wikipedia.org"
access = "all-access"
agent = "all-agents"
granularity = "daily"
start = "2015010100"
end = "2022013123"
url_daily = sprintf("https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/%s/%s/%s/%s/%s/%s", project, access, agent, granularity, start, end)
url_hourly = sprintf("https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/%s/%s/%s/%s/%s/%s", project, access, agent, "hourly", start, end)
daily_data = fromJSON(txt=url_daily)$items
hourly_data = fromJSON(txt= url_hourly)$items

```

##Converting Raw Data to Time Series
```{r}
msts_wiki_daily <- daily_data$views %>% 
  msts(seasonal.periods = c(7, 365), 
       start = decimal_date(as.Date("2015-07-01")))

autoplot(msts_wiki_daily)
```

##Splitting Test & Train Data
```{r}
wiki_daily_split <- ts_split(msts_wiki_daily, sample.out = 482)
```

##Visualising & Decomposing Time Series
```{r}
wiki_daily_decomp_train <- mstl(wiki_daily_split$train)
autoplot(wiki_daily_decomp_train)
```

##Differencing Seasonal Adjusted Component
```{r}
seasadj_wiki <- seasadj(wiki_daily_decomp_train)

#Test stat = 0.011
seasadj_wiki %>% 
  diff(lag =1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0142 
seasadj_wiki %>% 
  diff(lag =7)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.003
seasadj_wiki %>% 
  diff(lag =7)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 2.2636
seasadj_wiki %>% 
  diff(lag = 365)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0143
seasadj_wiki %>% 
  diff(lag =365)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()

trans_seasadj_wiki_1 <- seasadj_wiki %>%diff(lag = 1)
trans_seasadj_wiki_2 <- seasadj_wiki %>%diff(lag = 7)%>%diff(lag = 1)
autoplot(trans_seasadj_wiki_1)
autoplot(trans_seasadj_wiki_2)
```


##Benchmark Models
###Benchmark Model Creation
```{r}
b1 <- stlf(wiki_daily_split$train, method = "naive", robust = T)
b2 <- stlf(wiki_daily_split$train, method = "rwdrift", robust = T)
```

###Checking Residuals & Accuracy of Benchmark Models
```{r}
checkresiduals(b1)
checkresiduals(b2)
```

##ARIMA Models
###ACF & PACF Analysis for Differenced & Undifferenced Seasonal Adjusted Component
```{r}
ggtsdisplay(seasadj_wiki)
pacf(seasadj_wiki)
acf(seasadj_wiki)

ggtsdisplay(trans_seasadj_wiki_1)
pacf(trans_seasadj_wiki_1)
acf(trans_seasadj_wiki_1)

ggtsdisplay(trans_seasadj_wiki_2)
pacf(trans_seasadj_wiki_2)
acf(trans_seasadj_wiki_2)
```
###Shortlisting of ARIMA Models based of AICc
```{r}
#ASK PROF ON THURSDAY. Update: Prof say can just mention that the graphs got show  some MA or AR orders and that supports our models (e.g. we got MA and AR components)

A0 <- auto.arima(ts(seasadj_wiki, frequency = 7)) #(4,1,1)(2,0,2)[7]
A1 <- Arima(seasadj_wiki, order=c(1,1,3), seasonal = list(order = c(3,0,3), period = 7))
A2 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,0,2), period = 7))
A3 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(1,0,3), period = 7))
A4 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,1,2), period = 7))
A5 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,1,2), period = 7))
A6 <- Arima(seasadj_wiki, order=c(4,1,3), seasonal = list(order = c(2,1,2), period = 7))
A7 <- Arima(seasadj_wiki, order=c(4,1,1), seasonal = list(order = c(2,1,2), period = 7))

model_AIC = data.frame(model = c("A0", "A1", "A2", "A3", "A4", "A5", "A6", "A7"),
                       AIC = c(A0$aic, A1$aic, A2$aic, A3$aic, A4$aic, A5$aic, A6$aic, A7$aic))
model_AIC
```

###Checking Residuals & Accuracy of Shortlisted ARIMA Models
```{r}

#Only only that passed were (4,1,3)(2,1,2)[7] and (4,1,3)(1,0,2)[7]
# f0 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(4,1,1), 
#          seasonal = list(order = c(2,0,2), period = 7), robust = T)
# 
# f1 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(1,1,3), 
#          seasonal = list(order = c(3,0,3), period = 7), robust = T)
# 
# f2 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(2,1,3), 
#          seasonal = list(order = c(2,0,2), period = 7), robust = T)
# 
# f3 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(2,1,3), 
#          seasonal = list(order = c(1,0,3), period = 7), robust = T)
# 
# f4 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(2,1,3), 
#          seasonal = list(order = c(2,1,2), period = 7), robust = T)

f5 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(3,1,3), 
         seasonal = list(order = c(2,1,2), period = 7), robust = T)

f6 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(4,1,3), 
         seasonal = list(order = c(2,1,2), period = 7), robust = T)

f7 = stlm(wiki_daily_split$train, modelfunction = Arima, order=c(4,1,1), 
         seasonal = list(order = c(2,1,2), period = 7), robust = T)

# checkresiduals(forecast(f0))
# checkresiduals(forecast(f1))
# checkresiduals(forecast(f2))
# checkresiduals(forecast(f3))
# checkresiduals(forecast(f4))
checkresiduals(forecast(f5))
checkresiduals(forecast(f6))
checkresiduals(forecast(f7))

#Only f5 and f6 passed the Ljung-Box Test for the train set
accuracy(forecast(f5), wiki_daily_split$test)
accuracy(forecast(f6), wiki_daily_split$test)


autoplot(msts_wiki_daily)+autolayer(forecast(f5), PI = F, alpha = 0.7, col = "red")
```

##RNN
```{r}
# set a random seed for reproducability
set.seed(123)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions

max_len <- 6 # the number of previous examples we'll look at
batch_size <- 32 # number of sequences to look at at one time during training
total_epochs <- 50 # how many times we'll look @ the whole dataset while training our model

views <- daily_data$views

# Cut the text in overlapping sample sequences of max_len characters

# get a list of start indexes for our (overlapping) chunks
start_indexes <- seq(1, length(views) - (max_len + 1), by = 1)

# create an empty matrix to store our data in
views_matrix <- matrix(nrow = length(start_indexes), ncol = max_len + 1)

# fill our matrix with the overlapping slices of our dataset
for (i in 1:length(start_indexes)){
  views_matrix[i,] <- views[start_indexes[i]:(start_indexes[i] + max_len)]
}

# remove na's if you have them
if(anyNA(views_matrix)){
    views_matrix <- na.omit(views_matrix)
}

X <- views_matrix[,-ncol(views_matrix)]
y <- views_matrix[,ncol(views_matrix)]

training_index <- createDataPartition(y, p = .8, 
                                  list = FALSE, 
                                  times = 1)

# training data
X_train <- array(X[training_index,], dim = c(length(training_index), max_len, 1))
y_train <- y[training_index]

# testing data
X_test <- array(X[-training_index,], dim = c(length(y) - length(training_index), max_len, 1))
y_test <- y[-training_index]


model = keras_model_sequential() %>%   
   layer_simple_rnn(units=6, input_shape=c(6, 1), activation="relu") %>%  
   #layer_dense(units=6, activation = "relu") %>%  
   layer_dense(units=1, activation = "linear")
 
model %>% compile(loss = 'mse',
                  optimizer = 'RMSprop',
                  metrics = list("mean_squared_error"))
model %>% summary()

model %>% fit(X_train,y_train, epochs=total_epochs, batch_size= batch_size, shuffle = FALSE,validation_split = 0.2, callbacks = list(callback_early_stopping(monitor = 'val_loss', patience = 6, verbose = 0, restore_best_weights = T)))

rnn_outcome <- model %>% evaluate(X_test, y_test, verbose = 0)
rmse_rnn <- sqrt(rnn_outcome[2])
rmse_rnn
y_pred = model %>% predict(X_test)
x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
        col=c("red", "blue"), lty=1,cex=0.8)

```


