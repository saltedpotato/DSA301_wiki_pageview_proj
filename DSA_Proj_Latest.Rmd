---
title: "DSA301 Project"
author: "Everyone"
output: html_document
---
Questions:
1. Decompose first or transform first (benchmark models)
3. How to read the PACF & ACF graphs? Currently just using guess and check from changing models provided by auto.arima

##Loading Packages
```{r cars, include=FALSE}
rm(list = ls())
library(jsonlite)
library(lubridate)
library(forecast)
library(urca)
library(TSstudio)
library(prophet)
library(randomForest)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(randomForest) # for RF modelling 
```

### Reading CSV, Processing into TS Object, Visualisation of Data
```{r}
# daily_data = read_csv('dailydata.csv', show_col_types = FALSE)
# daily_data$views = daily_data$views / 1000000
# daily_data = filter(daily_data, date < as.Date("2022-1-1"))
# slice_head(daily_data, n = train_size) %>% write_csv(., "traindf.csv")
# slice_tail(daily_data, n = test_size) %>% write_csv(., "testdf.csv")
# write_csv(daily_data, "finalfulldf.csv")

daily_data = read_csv('finalfulldf.csv', show_col_types = FALSE)

# Putting data into TS Object
msts_wiki_daily = daily_data$views %>% msts(seasonal.periods = c(7, 365), start =c(2015, as.numeric(format(daily_data$date[1], "%j"))))

# Creating Train and Test Set
train_size = length(daily_data$date[year(daily_data$date) < 2021])
test_size = length(daily_data$date[year(daily_data$date) == 2021])

msts_split <- ts_split(msts_wiki_daily, sample.out = test_size)
msts_train = msts_split$train
msts_test = msts_split$test

prophet_data = rename(daily_data, y = views, ds = date)
prophet_train = slice_head(prophet_data, n = train_size)
prophet_test = slice_tail(prophet_data, n = test_size)
```

###Visualising STL decomposition
```{r}
daily_train_decomp = mstl(msts_train)
seasadj_wiki <- seasadj(daily_train_decomp)
autoplot(daily_train_decomp)
# Both the yearly seasonal pattern and the weekly seasonal pattern seem significant (in terms of impact on overall data), and therefore we do not rule any of them out at the moment.
```


## Differencing Seasonal Adjusted Component
```{r}
#No differencing: Test stat = 5
  seasadj_wiki %>% ur.kpss() %>% summary()

#Test stat = 0.011
seasadj_wiki %>% 
  diff(lag =1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0142 
seasadj_wiki %>% 
  diff(lag =7)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.003
seasadj_wiki %>% 
  diff(lag =7)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()

#Test stat = 2.2636
seasadj_wiki %>% 
  diff(lag = 365)%>%
  ur.kpss()%>%
  summary()

#Test stat = 0.0143
seasadj_wiki %>% 
  diff(lag =365)%>% 
  diff(lag = 1)%>%
  ur.kpss()%>%
  summary()
```


##Benchmark Models
###Benchmark Model Creation
```{r}
b1 <- stlf(msts_train, method = "naive", robust = T, h = test_size)
b2 <- stlf(msts_train, method = "rwdrift", robust = T, h = test_size)
checkresiduals(b1)
checkresiduals(b2)
accuracy(b1, msts_test)
accuracy(b2, msts_test)
# b1 RMSE - 7.920418
# b2 RMSE - 7.92038

# Ljung Box Test - We reject the null hypothesis that residuals are independently distributed, and we conclude that there is serial correlation. 
```
### Plotting Results
```{r}
autoplot(b1)
autoplot(b2)
# TRY TO PLOT THIS OUT
```

##ARIMA Models
###ACF & PACF Analysis for Differenced & Undifferenced Seasonal Adjusted Component
```{r}
# These two approaches to differencing yielded the lowest p value for the KPSS test.
trans_seasadj_wiki_1 <- seasadj_wiki %>%diff(lag = 1)
trans_seasadj_wiki_2 <- seasadj_wiki %>%diff(lag = 7)%>%diff(lag = 1)
autoplot(trans_seasadj_wiki_1)
autoplot(trans_seasadj_wiki_2)

ggtsdisplay(seasadj_wiki)
pacf(seasadj_wiki)
acf(seasadj_wiki)

ggtsdisplay(trans_seasadj_wiki_1)
pacf(trans_seasadj_wiki_1)
acf(trans_seasadj_wiki_1)

ggtsdisplay(trans_seasadj_wiki_2)
pacf(trans_seasadj_wiki_2)
acf(trans_seasadj_wiki_2)
```
###Shortlisting of ARIMA Models based of AICc
```{r}
#ASK PROF ON THURSDAY. Update: Prof say can just mention that the graphs got show  some MA or AR orders and that supports our models (e.g. we got MA and AR components)
# Using autoarima
A0 <- auto.arima(ts(seasadj_wiki, frequency = 7)) #(4,1,1)(2,0,2)[7]

# Variations based on the 1 non seasonal differencing
A1 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(3,0,3), period = 7))
A2 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,0,3), period = 7))
A3 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,0,2), period = 7))
# Model 4 is problematic, according to R data is not stationary
# A4 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,0,2), period = 7))

# Variations based on having both seasonal and non seasonal differencing
A5 <- Arima(seasadj_wiki, order=c(2,1,3), seasonal = list(order = c(2,1,1), period = 7))
A6 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,1,1), period = 7))
A7 <- Arima(seasadj_wiki, order=c(3,1,3), seasonal = list(order = c(2,1,2), period = 7))

# model_AIC = data.frame(model = c("A0", "A1", "A2", "A3", "A4", "A5", "A6","A7"),
#                        AIC = c(A0$aic, A1$aic, A2$aic, A3$aic, A4$aic, A5$aic, A6$aic, A7$aic))
model_AIC = data.frame(model = c("A0", "A1", "A2", "A3", "A4", "A5", "A6","A7"),
                       AIC = c(A0$aic, A1$aic, A2$aic, A3$aic, 100000, A5$aic, A6$aic, A7$aic))

model_AIC
# Based on this model AIC we are shortlisting the A0, A1, A2,A3 which all have similar AICs 
```

###Checking Residuals & Accuracy of Shortlisted ARIMA Models
```{r}

#Only only that passed were (4,1,3)(2,1,2)[7] and (4,1,3)(1,0,2)[7]
f0 = stlm(msts_train, modelfunction = Arima, order=c(4,1,1),
         seasonal = list(order = c(2,0,2), period = 7), robust = T) 

f1 = stlm(msts_train, modelfunction = Arima, order=c(2,1,3),
         seasonal = list(order = c(3,0,3), period = 7), robust = T) 

f2 = stlm(msts_train, modelfunction = Arima, order=c(2,1,3),
         seasonal = list(order = c(2,0,3), period = 7), robust = T) 

f3 = stlm(msts_train, modelfunction = Arima, order=c(2,1,3),
         seasonal = list(order = c(2,0,2), period = 7), robust = T) 

f4 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3),
         seasonal = list(order = c(2,0,2), period = 7), robust = T)

# PROBLEMATIC MODEL - Cannot be estimated
# f5 = stlm(msts_train, modelfunction = Arima, order=c(2,1,3), 
         # seasonal = list(order = c(2,1,1), period = 7), robust = T) 
# ERROR stating non-finite finite-difference value. This is related to the stationarity of the data according to stackoverflow. Cannot do MLE when the data is not stationary. 

f6 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3), 
         seasonal = list(order = c(2,1,1), period = 7), robust = T) 

f7 = stlm(msts_train, modelfunction = Arima, order=c(3,1,3), 
          seasonal = list(order = c(2,1,2), period = 7), robust = T)


# f7 = stlm(msts_train, modelfunction = Arima, order=c(4,1,2), 
          # seasonal = list(order = c(2,0,2), period = 7), robust = T)

checkresiduals(forecast(f0, h = test_size))
checkresiduals(forecast(f1, h = test_size))
checkresiduals(forecast(f2, h= test_size))
checkresiduals(forecast(f3, h = test_size))
checkresiduals(forecast(f4, h = test_size))
# checkresiduals(forecast(f5))
checkresiduals(forecast(f6, h = test_size))
checkresiduals(forecast(f7, h = test_size))

#Only f4, f6, f7 passed the Ljung-Box Test for the train set
accuracy(forecast(f4), msts_test)
# accuracy(forecast(f5), msts_test)
accuracy(forecast(f6), msts_test)
accuracy(forecast(f7), msts_test)

autoplot(msts_wiki_daily, series = "Original")+autolayer(forecast(f4), PI = F, alpha = 0.9, col = "red", series = "Forecast")+ scale_colour_manual(values=c("Original"="black","Forecast"="red"),
                      breaks=c("Original","Forecast"))
```

## Random Forest
```{r}
matrix_train <- data.frame(day1 = views_train_matrix[,1],
                           day2 = views_train_matrix[,2],
                           day3 = views_train_matrix[,3],
                           day4 = views_train_matrix[,4],
                           day5 = views_train_matrix[,5],
                           day6 = views_train_matrix[,6],
                           day7 = views_train_matrix[,7],
                           pred = views_train_matrix[,8])


matrix_test <- data.frame(day1 = views_matrix[,1],
                           day2 = views_matrix[,2],
                           day3 = views_matrix[,3],
                           day4 = views_matrix[,4],
                           day5 = views_matrix[,5],
                           day6 = views_matrix[,6],
                           day7 = views_matrix[,7])

rf_model <- randomForest(pred ~ ., data = matrix_train,
                         ntree = 1000, mtry = 2, nodesize = 5, importance = T)


y_pred <- predict(rf_model, matrix_test) 
y_test = y_pred[(length(y_pred)-length(views_test)+1):length(y_pred)]
rmse_rf <- sqrt(mean((views_test-y_test)^2))
rmse_rf

x_axes = seq(1:(length(views_test)))
plot(x_axes, views_test, type="l", col="red", lwd=2)
lines(x_axes, y_test, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)

```


## Facebook Prophet
```{r}
model = prophet(prophet_train, daily.seasonality = FALSE)

# Prediction
future = make_future_dataframe(model, periods = dim(prophet_test)[1])
prophet_forecast = predict(model, future) %>% slice_tail(., n = dim(prophet_test)[1])
accuracy(prophet_test$y, prophet_forecast$yhat)

# accuracy(forecast(f7, h=dim(prophet_test[1])), msts_test)
# accuracy(forecast(f7), msts_test)

# Evaluation
# prophet_plot_components(model, prophet_forecast)
# autoplot(prophet_forecast$yhat)

x_axes = seq(1:(length(prophet_forecast$yhat)))
plot(x_axes, prophet_test$y, type="l", col="red", lwd=2)
lines(x_axes, prophet_forecast$yhat, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)
```


