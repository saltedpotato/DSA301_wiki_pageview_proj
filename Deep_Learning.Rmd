# Libraries
```{r include=FALSE}
library(jsonlite)
library(lubridate)
library(forecast)
library(urca)
library(TSstudio)
library(prophet)
library(randomForest)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(randomForest) # for RF modelling
#source('dataprocessing.R')
```


### Importing data
```{r}
daily_data = read_csv('trainvaldf.csv', show_col_types = FALSE)

# Putting data into TS Object
msts_wiki_daily = daily_data$views %>% msts(seasonal.periods = c(7, 365), start =c(2015, as.numeric(format(daily_data$date[1], "%j"))), ts.frequency = 7)
# Creating Train and Test Set
train_size = length(daily_data$date[year(daily_data$date) < 2021])
val_size = dim(daily_data)[1] - train_size

msts_split <- ts_split(msts_wiki_daily, sample.out = val_size)
msts_train = msts_split$train
msts_test = msts_split$test
```


### Data Processing
```{r}
### STL Decomposition
daily_train_decomp = mstl(msts_train)
seasadj_wiki = seasadj(daily_train_decomp) %>% ts(., frequency = 7)

### Forecasted seasonal values using snaive
seas7 = seasonal(daily_train_decomp)[,1] %>% ts(., frequency = 7) %>% snaive(., h= val_size) %>%  forecast()
seas365 = seasonal(daily_train_decomp)[,2] %>% ts(., frequency = 365) %>%  snaive(.,h = val_size) %>% forecast()

### Exogenous Variables
#### 2020 Dummy
daily_data$y2020 = sapply(daily_data$date, function(x) {
  if (year(x) ==2020) {return(1)}
  return(0)
})

train2020_dummy = daily_data$y2020[1:train_size]
test2020_dummy = daily_data$y2020[(train_size+1): dim(daily_data)[1]]

#### Differenced Seasonally Adjusted Information
seasadj_wiki_differenced = seasadj_wiki %>% diff()
```


### FF NN TEST
```{r}
getNN_accuracy = function(data, p = 35, P= 5, xregterm = NULL, xregterm_forecasted= NULL){
    seasadj_forecast = nnetar(data, p =  p, P = P, xreg= xregterm) %>% forecast(., h= val_size, xreg = xregterm_forecasted)
    final_forecast = as.vector(seasadj_forecast$mean) + as.vector(seas7$mean) + as.vector(seas365$mean)
    return (accuracy(final_forecast, msts_test))
}

## Feedfoward NN, optimising for the number of seasonal lags and non-seasonal lags to be used within the model
m1 = getNN_accuracy(data = seasadj_wiki)
### RMSE xreg, p = 35, P = 5 is 10.82363, 10.727, 10.403
### Scale inputs doens't do anything - actually makes it worse

# Feeding differenced data into neural network instead
adjustedNN_new = nnetar(seasadj_wiki_new, p = 35, P = 5)
adjustedNN_new_pred = forecast(adjustedNN_new, h = val_size)$mean
transformed = as.vector(adjustedNN_new_pred)
transformed[1] = transformed[1] + as.vector(seasadj_wiki)[train_size]
transformed = cumsum(transformed)
final_pred_new = transformed + as.vector(seas7$mean) + as.vector(seas365$mean) 
accuracy(final_pred_new, msts_test)
# RMSE is 18.16
# RMSE is 11.83654
# The next time it became 13.95
# It is being evaluated on the same dataset, so it means that the parameters that are being estimated are constantly changing, based perhaps on the weight initialisation, the approach to gradient descent that is being used.... Highly variable result... 
```
### FF NN with exogenous variables
```{r}
# creating exogenous variables
# 1st variable: Differenced information forecasted using a feedforward neural network. 2nd Variable: 2020 Dummy
exogenous_var = matrix(c(seasadj_wiki_differenced, train2020_dummy), ncol = 2)
exogenous_var_val = matrix(c(adjustedNN_new_pred,test2020_dummy), ncol=2)

# Building the model
getNN_accuracy(data = seasadj_wiki, xregterm = exogenous_var, xregterm_forecasted = exogenous_var_val)
# RMSE 15.29
getNN_accuracy(data = seasadj_wiki, xregterm = exogenous_var[,1], xregterm_forecasted = exogenous_var_val[,1])
# RMSE is 16.3668
getNN_accuracy(data = seasadj_wiki, xregterm = exogenous_var[,2], xregterm_forecasted = exogenous_var_val[,2])
### RMSE is 10.86401
### RMSE is 14.57215
### RMSE is 13.98177
```



## FeedForward Neural Network
### FeedForward NN Training
```{r}

#NN without xreg on seasonal adjusted data
NN_model1 = stlm(msts_train, modelfunction=forecast::nnetar)
NN_forecast1 = forecast(NN_model1, h = val_size)
autoplot(msts_wiki_daily)+autolayer(NN_forecast1)

#NN with xreg non-seasonal lag
wiki_1 = diff(msts_train)
wiki1nn = nnetar(wiki_1)
forecastedgrowth1 = forecast(wiki1nn, val_size)
NN_model2 = nnetar(tail(msts_train, length(wiki_1)), 
                   xreg = wiki_1 )
NN_forecast2 = forecast(NN_model2, h = val_size, xreg = tail(forecastedgrowth1$x,val_size))

#NN with xreg seasonal lag
wiki_7 = diff(msts_train,7)
wiki7nn = nnetar(wiki_7)
forecastedgrowth7 = forecast(wiki7nn, val_size)
NN_model3 = nnetar(tail(msts_train, length(wiki_7)), xreg = wiki_7)
NN_forecast3 = forecast(NN_model3, h = val_size, xreg = tail(forecastedgrowth7$x,val_size))

#NN with xreg non-seasonal and seasonal lag
NN_model4 = nnetar(tail(msts_train, length(wiki_7)), xreg = cbind(tail(wiki_1, length(wiki_7)), wiki_7))
NN_forecast4 = forecast(NN_model4, h = val_size, xreg = cbind(tail(forecastedgrowth1$x, val_size), tail(forecastedgrowth7$x, val_size)))
```

### FeedForward NN Testing
```{r}
accuracy(NN_forecast1, msts_test)
accuracy(NN_forecast2, msts_test)
accuracy(NN_forecast3, msts_test)
accuracy(NN_forecast4, msts_test)

autoplot(msts_test)+autolayer(NN_forecast1, col = 'blue')
autoplot(msts_test)+autolayer(NN_forecast2, col = 'red')
autoplot(msts_test)+autolayer(NN_forecast3, col = 'green')
autoplot(msts_test)+autolayer(NN_forecast4, col = 'purple')
# autoplot(msts_wiki_daily)+autolayer(NN_forecast1, alpha = 0.7, col = 'red')

```


```{r LSTM, RNN model Functions}
lstmforecast = function(yvariable, forecasthorizon, epochs){
  normalization = c(mean(yvariable), sd(yvariable))
  train_norm = (yvariable - normalization[1]) / normalization[2]
  train_norm = as.matrix(train_norm)
  
  x_train_data = t(sapply(1:(length(train_norm) - forecasthorizon - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1), 1] ))
  x_train_arr = array(data = as.numeric(unlist(x_train_data)), dim = c( nrow(x_train_data), forecasthorizon,   1   )  )
  y_train_data = t(sapply( (1 + forecasthorizon):(length(train_norm) - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1)] ))
  y_train_arr = array( data = as.numeric(unlist(y_train_data)),  dim = c(  nrow(y_train_data),  forecasthorizon,   1    ) )
  x_test = yvariable[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
  x_test_scaled = (x_test - normalization[1]) / normalization[2]
  x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
  
  #####LSTM SETTINGS COPY PASTED FROM DOCS WITHOUT MODIFICATION###########
  lstm_model = keras_model_sequential()
  lstm_model %>%
    layer_lstm(units = 64, # size of the layer
               batch_input_shape = c(1, forecasthorizon, 1), # batch size, timesteps, features
               return_sequences = TRUE,
               stateful = TRUE) %>%
    # layer_dense(units=20, activation = "relu") %>%
    # fraction of the units to drop for the linear transformation of the inputs
    layer_dropout(rate = 0.5) %>%
    layer_lstm(units = 32,
               return_sequences = TRUE,
               stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    time_distributed(keras::layer_dense(units = 1))
  
  lstm_model %>%compile(loss = 'mae', optimizer = 'adam', metrics = 'mean_squared_error')     
  lstm_model %>% fit(x = x_train_arr, y = y_train_arr, batch_size = 1, epochs = epochs,shuffle = FALSE, verbose = 2)    
  lstm_forecast = lstm_model %>% predict(x_pred_arr, batch_size = 1) %>%.[, , 1]  #LINE X
  lstm_forecast = lstm_forecast * normalization[2] + normalization[1]
  
  return(list(model = lstm_model, values = lstm_forecast))  
}

rnnforecast = function(yvariable, forecasthorizon, epochs){
  normalization = c(mean(yvariable), sd(yvariable))
  train_norm = (yvariable - normalization[1]) / normalization[2]
  train_norm = as.matrix(train_norm)
  
  x_train_data = t(sapply(1:(length(train_norm) - forecasthorizon - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1), 1] ))
  x_train_arr = array(data = as.numeric(unlist(x_train_data)), dim = c( nrow(x_train_data), forecasthorizon,   1   )  )
  y_train_data = t(sapply( (1 + forecasthorizon):(length(train_norm) - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1)] ))
  y_train_arr = array( data = as.numeric(unlist(y_train_data)),  dim = c(  nrow(y_train_data),  forecasthorizon,   1    ) )
  x_test = yvariable[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
  x_test_scaled = (x_test - normalization[1]) / normalization[2]
  x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
  
  #####LSTM SETTINGS COPY PASTED FROM DOCS WITHOUT MODIFICATION###########
  rnn_model = keras_model_sequential()
  rnn_model %>%
    layer_simple_rnn(units = 30, # size of the layer
               batch_input_shape = c(1, forecasthorizon, 1), # batch size, timesteps, features
               return_sequences = TRUE,
               stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    layer_simple_rnn(units=30,
                     return_sequences = TRUE,
                     stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    # fraction of the units to drop for the linear transformation of the inputs

    time_distributed(keras::layer_dense(units = 1))
  
  rnn_model %>%compile(loss = 'mae', optimizer = 'adam', metrics = 'mean_squared_error')     
  rnn_model %>% fit(x = x_train_arr, y = y_train_arr, 
                    batch_size = 1, epochs = epochs,
                    shuffle = FALSE, verbose = 2)

  rnn_forecast = rnn_model %>% predict(x_pred_arr, batch_size = 1) %>%.[, , 1]  #LINE X
  rnn_forecast = rnn_forecast * normalization[2] + normalization[1]
  
  return(list(model = rnn_model, values = rnn_forecast)) 
}


```

```{r RNN}
var = msts_wiki_daily
forecasthorizon = val_size

##DO NOT REALLY NEED TO EDIT THIS PART######
forecast = rnnforecast(var,forecasthorizon, 5)

y_pred <- forecast$values
y_test <- var[(length(var) - val_size + 1):length(var)]
sqrt(mean((y_test - y_pred)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
        col=c("red", "blue"), lty=1,cex=0.8)

forecast$model %>% save_model_hdf5("RNN.h5")
```


```{r LSTM only}
##LSTM Only
var = msts_wiki_daily
forecasthorizon = val_size

forecast = lstmforecast(var,forecasthorizon, 10)
y_pred <- forecast$values
y_test <- var[(length(var) - val_size + 1):length(var)]
sqrt(mean((y_test - y_pred)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
        col=c("red", "blue"), lty=1,cex=0.8)

forecast$model %>% save_model_hdf5("LSTM.h5")

# rachel = load_model_hdf5("LSTM_Rachel_v1.h5")
# 
# normalization = c(mean(var), sd(var))
#   train_norm = (var - normalization[1]) / normalization[2]
#   train_norm = as.matrix(train_norm)
#   x_test = var[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
#   x_test_scaled = (x_test - normalization[1]) / normalization[2]
#   x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
# y_pred = rachel%>%predict(x_pred_arr)%>%.[, , 1]  #LINE X
# y_pred = y_pred * normalization[2] + normalization[1]
# sqrt(mean((y_test - y_pred)^2))
# 
# x_axes = seq(1:length(y_pred))
# plot(x_axes, y_test, type="l", col="red", lwd=2)
# lines(x_axes, y_pred, col="blue",lwd=2)
# legend("topleft", legend=c("y-original", "y-predicted"),
#         col=c("red", "blue"), lty=1,cex=0.8)

```
```{r Arima on seasadj, RNN on seasonal 7 and seasonal 365}
forecasthorizon = val_size
y_test <- daily_data$views[(length(daily_data$views) - forecasthorizon + 1):length(daily_data$views)]
##Arima on trend, RNN on seasonal'
data_decomp <- mstl(msts_wiki_daily)
seas_adj_comp <- seasadj(data_decomp)
train_seasadj <- seas_adj_comp[1:(length(seas_adj_comp) - forecasthorizon)]

arima_seasadj <- Arima(train_seasadj, order=c(3,1,3), seasonal = list(order = c(2,0,3), period = 7))

y_pred_seasadj <- forecast(arima_seasadj, h = forecasthorizon)
y_pred_seasadj <- y_pred_seasadj$mean 


var_seas = seasonal(data_decomp)[,1] + seasonal(data_decomp)[,2]

forecast_seas = rnnforecast(var_seas,forecasthorizon, 10)
y_pred_seas <- forecast_seas$values 


y_pred <- y_pred_seasadj + y_pred_seas
sqrt(mean((y_pred - y_test)^2))


x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)

forecast_seas$model %>% save_model_hdf5("rnn_seasonal.h5")
```

```{r Arima on seasadj, LSTM on seasonal 7 and seasonal 365}
forecasthorizon = val_size
y_test <- daily_data$views[(length(daily_data$views) - forecasthorizon + 1):length(daily_data$views)]
##Arima on trend, LSTM on seasonal'
data_decomp <- mstl(msts_wiki_daily)
seas_adj_comp <- seasadj(data_decomp)
train_seasadj <- seas_adj_comp[1:(length(seas_adj_comp) - forecasthorizon)]

arima_seasadj <- Arima(train_seasadj, order=c(3,1,3), seasonal = list(order = c(2,0,3), period = 7))

y_pred_seasadj <- forecast(arima_seasadj, h = forecasthorizon)
y_pred_seasadj <- y_pred_seasadj$mean 


var_seas = seasonal(data_decomp)[,1] + seasonal(data_decomp)[,2]

forecast_seas = lstmforecast(var_seas,forecasthorizon, 10)
y_pred_seas <- forecast_seas$values 


y_pred <- y_pred_seasadj + y_pred_seas
sqrt(mean((y_pred - y_test)^2))


x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)

forecast_seas$model %>% save_model_hdf5("lstm_seasonal.h5")
```


```{r with Arima on seasadj, Prophet on seasonal}
data_decomp <- mstl(msts_wiki_daily)
seas_adj_comp <- seasadj(data_decomp)
train_seasadj <- seas_adj_comp[1:(length(seas_adj_comp) - forecasthorizon)]
var_seas = seasonal(data_decomp)[,1] + seasonal(data_decomp)[,2]


y_test <- daily_data$views[(length(daily_data$views) - forecasthorizon + 1):length(daily_data$views)]


arima_seasadj <- Arima(train_seasadj, order=c(3,1,3), seasonal = list(order = c(2,0,3), period = 7))
y_pred_seasadj <- forecast(arima_seasadj, h = forecasthorizon)
y_pred_seasadj <- y_pred_seasadj$mean 

forecast_seasadj = lstmforecast(seas_adj_comp,forecasthorizon, 10)
y_pred_seasadj <- forecast_seasadj$values 

prophet_data = rename(daily_data, y = views, ds = date)
prophet_data$y = data.frame(var_seas)[,1]
prophet_train = slice_head(prophet_data, n = train_size)
prophet_test = slice_tail(prophet_data, n = val_size)


model = prophet(data.frame(prophet_train), daily.seasonality = FALSE)

# Prediction
future = make_future_dataframe(model, periods = forecasthorizon)
prophet_forecast = predict(model, future)
prophet_predict = predict(model, future) %>% slice_tail(., n = forecasthorizon)
accuracy(prophet_test$y, prophet_predict$yhat)

y_pred <- y_pred_seasadj + prophet_predict$yhat
sqrt(mean((y_pred - y_test)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)
```


```{r with LSTM on seasadj, Prophet on seas}
data_decomp <- mstl(msts_wiki_daily)
seas_adj_comp <- seasadj(data_decomp)
var_seas = seasonal(data_decomp)[,1] + seasonal(data_decomp)[,2]
y_test <- daily_data$views[(length(daily_data$views) - forecasthorizon + 1):length(daily_data$views)]

forecast_seasadj = lstmforecast(seas_adj_comp,forecasthorizon, 10)
y_pred_seasadj <- forecast_seasadj$values 

prophet_data = rename(daily_data, y = views, ds = date)
prophet_data$y = data.frame(var_seas)[,1]
prophet_train = slice_head(prophet_data, n = train_size)
prophet_test = slice_tail(prophet_data, n = val_size)


model = prophet(data.frame(prophet_train), daily.seasonality = FALSE)

# Prediction
future = make_future_dataframe(model, periods = forecasthorizon)
prophet_forecast = predict(model, future)
prophet_predict = predict(model, future) %>% slice_tail(., n = forecasthorizon)
accuracy(prophet_test$y, prophet_predict$yhat)

y_pred <- y_pred_seasadj + prophet_predict$yhat
sqrt(mean((y_pred - y_test)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)
```