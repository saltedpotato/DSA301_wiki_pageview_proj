# Libraries
```{r include=FALSE}
library(jsonlite)
library(lubridate)
library(forecast)
library(urca)
library(TSstudio)
library(prophet)
library(randomForest)
library(keras) # for deep learning
library(tidyverse) # general utility functions
library(caret) # machine learning utility functions
library(randomForest) # for RF modelling
#source('dataprocessing.R')
```


### Importing data
```{r}
rm(list = ls())
daily_data = read_csv('trainvaldf.csv', show_col_types = FALSE)

# Putting data into TS Object
msts_wiki_daily = daily_data$views %>% msts(seasonal.periods = c(7, 365), start =c(2015, as.numeric(format(daily_data$date[1], "%j"))), ts.frequency = 7)
# Creating Train and Test Set
train_size = length(daily_data$date[year(daily_data$date) < 2021])
val_size = dim(daily_data)[1] - train_size

msts_split <- ts_split(msts_wiki_daily, sample.out = val_size)
msts_train = msts_split$train
msts_test = msts_split$test
```



## FeedForward Neural Network
### FeedForward NN Training
```{r}

#NN without xreg on seasonal adjusted data
NN_model1 = stlm(msts_train, modelfunction=forecast::nnetar)
NN_forecast1 = forecast(NN_model1, h = val_size)
autoplot(msts_wiki_daily)+autolayer(NN_forecast1)

#NN with xreg non-seasonal lag
wiki_1 = diff(msts_train)
wiki1nn = nnetar(wiki_1)
forecastedgrowth1 = forecast(wiki1nn, val_size)
NN_model2 = nnetar(tail(msts_train, length(wiki_1)), 
                   xreg = wiki_1 )
NN_forecast2 = forecast(NN_model2, h = val_size, xreg = tail(forecastedgrowth1$x,val_size))

#NN with xreg seasonal lag
wiki_7 = diff(msts_train,7)
wiki7nn = nnetar(wiki_7)
forecastedgrowth7 = forecast(wiki7nn, val_size)
NN_model3 = nnetar(tail(msts_train, length(wiki_7)), xreg = wiki_7)
NN_forecast3 = forecast(NN_model3, h = val_size, xreg = tail(forecastedgrowth7$x,val_size))

#NN with xreg non-seasonal and seasonal lag
NN_model4 = nnetar(tail(msts_train, length(wiki_7)), xreg = cbind(tail(wiki_1, length(wiki_7)), wiki_7))
NN_forecast4 = forecast(NN_model4, h = val_size, xreg = cbind(tail(forecastedgrowth1$x, val_size), tail(forecastedgrowth7$x, val_size)))
```

### FeedForward NN Testing
```{r}
accuracy(NN_forecast1, msts_test)
accuracy(NN_forecast2, msts_test)
accuracy(NN_forecast3, msts_test)
accuracy(NN_forecast4, msts_test)

autoplot(msts_test)+autolayer(NN_forecast1, col = 'blue')
autoplot(msts_test)+autolayer(NN_forecast2, col = 'red')
autoplot(msts_test)+autolayer(NN_forecast3, col = 'green')
autoplot(msts_test)+autolayer(NN_forecast4, col = 'purple')

autoplot(msts_wiki_daily)+autolayer(NN_forecast1, alpha = 0.7, col = 'red')

```

```{r LSTM, RNN model Functions}
lstmforecast = function(yvariable, forecasthorizon, epochs){
  normalization = c(mean(yvariable), sd(yvariable))
  train_norm = (yvariable - normalization[1]) / normalization[2]
  train_norm = as.matrix(train_norm)
  
  x_train_data = t(sapply(1:(length(train_norm) - forecasthorizon - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1), 1] ))
  x_train_arr = array(data = as.numeric(unlist(x_train_data)), dim = c( nrow(x_train_data), forecasthorizon,   1   )  )
  y_train_data = t(sapply( (1 + forecasthorizon):(length(train_norm) - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1)] ))
  y_train_arr = array( data = as.numeric(unlist(y_train_data)),  dim = c(  nrow(y_train_data),  forecasthorizon,   1    ) )
  x_test = yvariable[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
  x_test_scaled = (x_test - normalization[1]) / normalization[2]
  x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
  
  #####LSTM SETTINGS COPY PASTED FROM DOCS WITHOUT MODIFICATION###########
  lstm_model = keras_model_sequential()
  lstm_model %>%
    layer_lstm(units = 64, # size of the layer
               batch_input_shape = c(1, forecasthorizon, 1), # batch size, timesteps, features
               return_sequences = TRUE,
               stateful = TRUE) %>%
    # layer_dense(units=20, activation = "relu") %>%
    # fraction of the units to drop for the linear transformation of the inputs
    layer_dropout(rate = 0.5) %>%
    layer_lstm(units = 32,
               return_sequences = TRUE,
               stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    time_distributed(keras::layer_dense(units = 1))
  
  lstm_model %>%compile(loss = 'mae', optimizer = 'adam', metrics = 'mean_squared_error')     
  lstm_model %>% fit(x = x_train_arr, y = y_train_arr, batch_size = 1, epochs = epochs,shuffle = FALSE, verbose = 2)    
  lstm_forecast = lstm_model %>% predict(x_pred_arr, batch_size = 1) %>%.[, , 1]  #LINE X
  lstm_forecast = lstm_forecast * normalization[2] + normalization[1]
  
  return(list(model = lstm_model, values = lstm_forecast))  
}

rnnforecast = function(yvariable, forecasthorizon, epochs){
  normalization = c(mean(yvariable), sd(yvariable))
  train_norm = (yvariable - normalization[1]) / normalization[2]
  train_norm = as.matrix(train_norm)
  
  x_train_data = t(sapply(1:(length(train_norm) - forecasthorizon - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1), 1] ))
  x_train_arr = array(data = as.numeric(unlist(x_train_data)), dim = c( nrow(x_train_data), forecasthorizon,   1   )  )
  y_train_data = t(sapply( (1 + forecasthorizon):(length(train_norm) - forecasthorizon + 1), function(x) train_norm[x:(x + forecasthorizon - 1)] ))
  y_train_arr = array( data = as.numeric(unlist(y_train_data)),  dim = c(  nrow(y_train_data),  forecasthorizon,   1    ) )
  x_test = yvariable[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
  x_test_scaled = (x_test - normalization[1]) / normalization[2]
  x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
  
  #####LSTM SETTINGS COPY PASTED FROM DOCS WITHOUT MODIFICATION###########
  rnn_model = keras_model_sequential()
  rnn_model %>%
    layer_simple_rnn(units = 30, # size of the layer
               batch_input_shape = c(1, forecasthorizon, 1), # batch size, timesteps, features
               return_sequences = TRUE,
               stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    layer_simple_rnn(units=30,
                     return_sequences = TRUE,
                     stateful = TRUE) %>%
    layer_dropout(rate = 0.5) %>%
    # fraction of the units to drop for the linear transformation of the inputs

    time_distributed(keras::layer_dense(units = 1))
  
  rnn_model %>%compile(loss = 'mae', optimizer = 'adam', metrics = 'mean_squared_error')     
  rnn_model %>% fit(x = x_train_arr, y = y_train_arr, 
                    batch_size = 1, epochs = epochs,
                    shuffle = FALSE, verbose = 2)

  rnn_forecast = rnn_model %>% predict(x_pred_arr, batch_size = 1) %>%.[, , 1]  #LINE X
  rnn_forecast = rnn_forecast * normalization[2] + normalization[1]
  
  return(list(model = rnn_model, values = rnn_forecast)) 
}


```

```{r RNN}
##DO NOT REALLY NEED TO EDIT THIS PART######
forecast = rnnforecast(var,forecasthorizon, 5)

y_pred <- forecast$values
y_test <- var[(length(var) - val_size + 1):length(var)]
sqrt(mean((y_test - y_pred)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
        col=c("red", "blue"), lty=1,cex=0.8)

forecast$model %>% save_model_hdf5("RNN.h5")
```


```{r LSTM only}
##LSTM Only
var = msts_wiki_daily
forecasthorizon = val_size

forecast$model %>% save_model_hdf5("LSTM.h5")

# rachel = load_model_hdf5("LSTM_Rachel_v1.h5")
# 
# normalization = c(mean(var), sd(var))
#   train_norm = (var - normalization[1]) / normalization[2]
#   train_norm = as.matrix(train_norm)
#   x_test = var[(nrow(train_norm) - 2*forecasthorizon + 1):(nrow(train_norm) - forecasthorizon + 1)]
#   x_test_scaled = (x_test - normalization[1]) / normalization[2]
#   x_pred_arr = array(data = x_test_scaled,  dim = c( 1, forecasthorizon,  1 ) )
# y_pred = rachel%>%predict(x_pred_arr)%>%.[, , 1]  #LINE X
# y_pred = y_pred * normalization[2] + normalization[1]
# sqrt(mean((y_test - y_pred)^2))
# 
# x_axes = seq(1:length(y_pred))
# plot(x_axes, y_test, type="l", col="red", lwd=2)
# lines(x_axes, y_pred, col="blue",lwd=2)
# legend("topleft", legend=c("y-original", "y-predicted"),
#         col=c("red", "blue"), lty=1,cex=0.8)

```



```{r RNN}
##DO NOT REALLY NEED TO EDIT THIS PART######
forecast = lstmforecast(var,forecasthorizon, 10)

y_pred <- forecast$values
y_test <- var[(length(var) - val_size + 1):length(var)]
sqrt(mean((y_test - y_pred)^2))

x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
        col=c("red", "blue"), lty=1,cex=0.8)

forecast$model %>% save_model_hdf5("LSTM.h5")

```

```{r Arima on seasadj, LSTM on seasonal 7 and seasonal 365}
forecasthorizon = val_size
y_test <- daily_data$views[(length(daily_data$views) - forecasthorizon + 1):length(daily_data$views)]
##Arima on trend, LSTM on seasonal'
data_decomp <- mstl(msts_wiki_daily)
seas_adj_comp <- seasadj(data_decomp)
train_seasadj <- seas_adj_comp[1:(length(seas_adj_comp) - forecasthorizon)]

arima_seasadj1 <- auto.arima(train_seasadj, seasonal = F)
arima_seasadj2 <-  Arima(train_seasadj, order = c(4,1,3))
arima_seasadj3 <- Arima(train_seasadj, order=c(3,1,3), seasonal = list(order = c(2,0,3), period = 7))
arima_seasadj1
arima_seasadj2
arima_seasadj3

y_pred_seasadj <- forecast(arima_seasadj3, h = forecasthorizon)
y_pred_seasadj <- y_pred_seasadj$mean 
sqrt(mean((y_pred_seasadj - seas_adj_comp[(length(seas_adj_comp) - forecasthorizon + 1):length(seas_adj_comp)])^2))


var_seas = var365

forecast_seas = lstmforecast(var_seas,forecasthorizon, 5)
y_pred_seas <- forecast_seas$values 


y_pred <- y_pred_seasadj + y_pred_seas
sqrt(mean((y_pred - y_test)^2))


x_axes = seq(1:length(y_pred))
plot(x_axes, y_test, type="l", col="red", lwd=2)
lines(x_axes, y_pred, col="blue",lwd=2)
legend("topleft", legend=c("y-original", "y-predicted"),
       col=c("red", "blue"), lty=1,cex=0.8)

forecast_seas7$model %>% save_model_hdf5("lstm_seasonal7.h5")
forecast_seas365$model %>% save_model_hdf5("lstm_seasonal365.h5")
```


```{r with Prophet}
prophet_data7 = rename(daily_data, y = views, ds = date)
prophet_data7$y = data.frame(var7)[,1]
prophet_train7 = slice_head(prophet_data7, n = train_size)
prophet_test7 = slice_tail(prophet_data7, n = val_size)


model7 = prophet(data.frame(prophet_train7), daily.seasonality = FALSE)

# Prediction7
future7 = make_future_dataframe(model7, periods = forecasthorizon)
prophet_forecast7 = predict(model7, future7)
prophet_predict7 = predict(model7, future7) %>% slice_tail(., n = forecasthorizon)
accuracy(prophet_test7$y, prophet_predict7$yhat)


y_pred <- y_pred_seasadj + prophet_predict365$yhat + y_pred_seas7 #lstm
sqrt(mean((y_pred - y_test)^2))
```


```{r with LSTM on seasadj, Prophet on seas}

forecast_seasadj = lstmforecast(seas_adj_comp,forecasthorizon)
y_pred_seasadj <- forecast_seasadj$values 


prophet_data = rename(daily_data, y = views, ds = date)
prophet_data$y = data.frame(var_seas)[,1]
prophet_train = slice_head(prophet_data, n = train_size)
prophet_test = slice_tail(prophet_data, n = val_size)


model = prophet(data.frame(prophet_train), daily.seasonality = FALSE)

# Prediction7
future = make_future_dataframe(model, periods = forecasthorizon)
prophet_forecast = predict(model, future)
prophet_predict = predict(model, future) %>% slice_tail(., n = forecasthorizon)
accuracy(prophet_test$y, prophet_predict$yhat)

y_pred <- y_pred_seasadj + prophet_predict$yhat + y_pred_seas7 #lstm
sqrt(mean((y_pred - y_test)^2))
```