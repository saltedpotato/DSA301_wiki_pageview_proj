---
title: "R Notebook"

---
## Question 1
```{r Q1 install libraries}
library(fpp2)
library(forecast)
library(urca)
```

```{r Q1 (a)}
autoplot(ma(usmelec,12,centre = TRUE))

```

```{r Q1 (b)}
boxcox_usmelec <- BoxCox(usmelec,BoxCox.lambda(usmelec))
autoplot(boxcox_usmelec)
```
From part (a), we can see that the variance of the autoplot is not constant, and therefore BoxCox transformation should be employed.


```{r Q1 (c)}
boxcox_usmelec %>%
  ur.kpss()%>%
  summary()

nsdiffs(boxcox_usmelec) #1
ndiffs(diff(boxcox_usmelec,12)) #1

boxcox_usmelec%>%
  diff(lag = 12) %>%
  diff() %>%
  ur.kpss()%>%
  summary()

acf(boxcox_usmelec)
acf(diff(diff(boxcox_usmelec,12)))
```
From the KPSS test, we can see that the data is not stationary with a test statistic of 7.8337, which is larger than the critical values in 1pct. Hence, we check if differencing is needed using nsdiffs and ndiffs. After differencing, the KPSS test statistic is lowered to 0.0167, which is lower than the critical value in 10pct.

```{r Q1 (d)}
ggtsdisplay(boxcox_usmelec)
ggtsdisplay(diff(diff(boxcox_usmelec,12)))
```
Based on the PACF plot of the transformed data, there may be presence of seasonal MA and non-seasonal MA due to the exponentially decaying PACF values at the seasonal lags and non-seasonal lags respectively. With reference to the ACF plot, seasonal MA could be 1 due to the spike at lag 12 and non-seasonal MA could be 3 due to the 3 significant spikes in ACF.

For AR, it is difficult to distinguish what order it has for both non-seasonal and seasonal as PACF plot could have been affected by the MA portion.From the ACF plot, we assume it is not a pure MA model as there are significant spikes outside of the relevant seasonal and non seasonal lags. From PACF, seasonal AR order could be 3 due to significant spikes at seasonal lags in PACF, and non-seasonal AR order could be 2 due to significant spikes in first 2 lags. It could also be 0 or 1 as PACF spikes might be a result of MA instead of AR.

As it is difficult to distinguish the order based on the ACF and PACF plots alone, we plan to test a few models by changing the orders around.
```{r}
m1 <- auto.arima(usmelec, lambda = "auto", biasadj = T) #(1,1,3)(2,1,1)[12]
m2 <- Arima(usmelec, order = c(2,1,3), seasonal = c(3,1,1), lambda = "auto", biasadj = T)
m3 <- Arima(usmelec, order = c(0,1,3), seasonal = c(2,1,1), lambda = "auto", biasadj = T)
m4 <- Arima(usmelec, order = c(1,1,3), seasonal = c(2,1,2), lambda = "auto", biasadj = T)
m5 <- Arima(usmelec, order = c(1,1,2), seasonal = c(2,1,1), lambda = "auto", biasadj = T)
m6 <- Arima(usmelec, order = c(1,1,1), seasonal = c(2,1,1), lambda = "auto", biasadj = T)
m7 <- Arima(usmelec, order = c(1,1,1), seasonal = c(3,1,1), lambda = "auto", biasadj = T)

model_AIC = data.frame(model = c("m1", "m2", "m3", "m4", "m5", "m6", "m7"),
                       AIC = c(m1$aic, m2$aic, m3$aic, m4$aic, m5$aic, m6$aic, m7$aic))
model_AIC

```
Best model based on AIC is m6 with lowest AIC value of -5082.634 compared to the other models.

```{r Q1 (e)}
checkresiduals(m1)
checkresiduals(m3)
checkresiduals(m5)
checkresiduals(m6)
```

Since m3 and m5 has an AIC close to m6, we will consider it as well. 

From the checkresiduals test, all models both pass the Ljung-box test with p-value of 0.07454, 0.07518, 0.08662, 0.08318 respectively at 5% sig. level.
Hence, all models have residuals resembling resembling noise at 5% sig level.


```{r Q1 (f)}
latest_data <- read.csv("HW2 Q1 Cleaned Data.csv")
latest_data_ts <- ts(latest_data["Amount"], start = c(2013,7), deltat = 1/12)
accuracy(forecast(m1,h = 15*12), latest_data_ts)
accuracy(forecast(m3,h = 15*12), latest_data_ts)
accuracy(forecast(m5,h = 15*12), latest_data_ts)
accuracy(forecast(m6,h = 15*12), latest_data_ts)

autoplot(forecast(m3,h = 15*12), PI = F)
autoplot(forecast(m3,h = 15*12), PI = T)
```

From the accuracy tests, m3 attained the best RMSE score in the train and test set. Hence, m1 is the best model to use for prediction.

Q1 (g)
```{r}
m3_forecast <-forecast(m3,h = 15*12)
interval_range_80 <- m3_forecast$upper[,1]-m3_forecast$lower[,1]
m3_forecast$mean/interval_range_80
```

Since the predictions of m7 is reasonably accurate, the general predictability of the trend, seasonality, and heteroskedastic attributes of the time series makes for a more accurate forecast. With such long and stable patterns in the data, predictions up to a decade would not be unseasonable. Afterwards, predictions may no longer be accurate, and should no longer be used.

#Question 2

### Part 1
```{r include=FALSE}
rm(list = ls())
library(fpp2)
library(TSstudio)
library(vars)
```
```{r eval=FALSE, include=FALSE}
head(visnights)
```
Total quarterly visitor nights (in millions) from 1998-2016 for twenty regions of Australia within six states. The states are: New South Wales, Queensland, South Australia, Victoria, Western Australia, and Other

### Part 2
```{r}
autoplot(visnights)
```
There does not appear to be a long term directional trend. However, there does appear to be yearly seasonality in the data. 

### Part3
Granger causation means that a variable is affected by lagged values of another variable. It is likely that the total quarterly visitor nights in 2 adjacent regions within the same state would Granger cause each other. An individual deciding to stay in a particular state has the choice of whether to stay in one of those regions, and they are therefore substitute goods. Hence, we have chosen NSWNthIn and NSWSthIn. 

### Part 4
```{r}
index1 = which(colnames(visnights) == "NSWNthIn")
index2 = which(colnames(visnights) == "NSWSthIn")

print(index1)
print(index2)

autoplot(visnights[,index1])
autoplot(visnights[,index2])
```
```{r}
# Check for whether seasonal differencing is required
nsdiffs(visnights[,index1])
nsdiffs(visnights[,index2])
ndiffs(visnights[,index1])
ndiffs(visnights[,index2])
```
From our analysis of nsdiffs and ndiffs, the variables are already in their stationary form, without having to do any differencing.

### Part 5
```{r}
grangertest(visnights[,index1], visnights[,index2], order = 1)
grangertest(visnights[,index2], visnights[,index1], order = 1)
```
The p value from both granger causality tests are low (below 10%). The p value from the granger casuality test testing whether NSWNthIn granger causes NSWSthIn is 9.483e-05, and p value from the opposite granger test is 0.07582. 


### Part 6
```{r}
combined_df = cbind(visnights[,index1],visnights[,index2])
VARselect(combined_df, lag.max = 8)
```

```{r}
var1 = VAR(combined_df, p =1, type = "const")
serial.test(var1, lags.pt = 10, type = "PT.asymptotic")
```
We perform the Ljung Box test on the residuals. The probability of achieving a test statistic at least or more extreme than that which we achieve is 0.1935. Hence, we reject the null hypothesis - there is indeed no time series information in the residuals. 
